{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takayuki/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from gangen.cdcgan import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/takayuki/Desktop/sem6/DL/mini_proj_TRAFFIC/data/'\n",
    "train_dir = os.path.join(data_dir, 'preprocessed', 'Train')\n",
    "\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.08, 0.08), scale=(0.9, 1.1), shear=5),\n",
    "    transforms.Resize((32, 32)),\n",
    "    \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "   \n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.3),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.01, 0.04), ratio=(0.5, 2.0), value=0), # value=0 for black box\n",
    "\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root = train_dir, transform=data_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "noise_dim = 100\n",
    "n_classes = 43\n",
    "embedding_dim = 64\n",
    "lambda_gp = 10\n",
    "\n",
    "k_steps_D = 1\n",
    "k_steps_G = 1 \n",
    "log_interval = 5  # Log images every N epochs\n",
    "checkpoint_interval = 10 # Save checkpoint every N epochs\n",
    "\n",
    "label_smoothing = 0.0\n",
    "learning_rate_g = 0.0002\n",
    "learning_rate_d = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [ 210. 2220. 2010. 1320. 2100. 2160.  780.  630.  420. 1110. 1200.  210.\n",
      " 2250.  360.  330.  390.  510.  270. 1500.  600.  240.  540.  270. 1410.\n",
      "  450.  780.  240.  689.  420. 1200.  390.  210. 2070.  300. 1980.  360.\n",
      "  240.  240. 1860.  420. 1440. 1410. 1470.]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\n",
    "    full_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "targets = full_dataset.targets\n",
    "class_counts = np.bincount(targets, minlength=n_classes)\n",
    "class_counts = np.array(class_counts, dtype=np.float32)\n",
    "    \n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / np.sum(class_weights) * n_classes  # Normalize\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3, 32, 32])\n",
      "Label shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for inp, lab in data_loader:\n",
    "    print(\"Input shape:\", inp.shape)\n",
    "    print(\"Label shape:\", lab.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(noise_dim=noise_dim, n_classes=n_classes, embedding_dim=embedding_dim).to(device)\n",
    "D = Discriminator(n_classes=n_classes, embedding_dim=embedding_dim).to(device)\n",
    "\n",
    "# Set up optimizers\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=learning_rate_g, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=learning_rate_d, betas=(beta1, beta2))\n",
    "\n",
    "# Loss function \n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard\n",
    "log_dir = 'logs/gan_training_' + time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(num_samples=16, fixed_noise=None, fixed_labels=None):\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        if fixed_noise is None:\n",
    "            fixed_noise = torch.randn(num_samples, noise_dim, device=device)\n",
    "        if fixed_labels is None:\n",
    "            # Generate samples across different classes\n",
    "            fixed_labels = torch.arange(0, min(n_classes, num_samples), device=device)\n",
    "            # Repeat labels if num_samples > n_classes\n",
    "            fixed_labels = fixed_labels.repeat(num_samples // min(n_classes, num_samples) + 1)[:num_samples]\n",
    "        \n",
    "        fake_samples = G(fixed_noise, fixed_labels)\n",
    "        \n",
    "    # Convert to displayable format\n",
    "    fake_samples = fake_samples.detach().cpu().numpy()\n",
    "    # Move channel dimension to the end for plotting\n",
    "    fake_samples = np.transpose(fake_samples, (0, 2, 3, 1))\n",
    "    # Denormalize\n",
    "    fake_samples = fake_samples * 0.5 + 0.5\n",
    "    fake_samples = np.clip(fake_samples, -1, 1)\n",
    "    \n",
    "    return fake_samples, fixed_labels.cpu().numpy()\n",
    "\n",
    "# Create a grid of images\n",
    "def create_image_grid(images, labels, nrow=4):\n",
    "    ncol = images.shape[0] // nrow\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(12, 12))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < images.shape[0]:\n",
    "            ax.imshow(images[i])\n",
    "            ax.set_title(f\"Class: {labels[i]}\")\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Function to save checkpoint\n",
    "def save_checkpoint(G, D, optimizer_G, optimizer_D, epoch, filename='checkpoint.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'generator_state_dict': G.state_dict(),\n",
    "        'discriminator_state_dict': D.state_dict(),\n",
    "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "        'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "    }, filename)\n",
    "\n",
    "# Create fixed noise for visualization\n",
    "fixed_noise = torch.randn(16, noise_dim, device=device)\n",
    "fixed_labels = torch.arange(0, min(n_classes, 16), device=device).repeat(16 // min(n_classes, 16) + 1)[:16]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with k_steps_D=1, k_steps_G=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Summary - Avg D Loss: 0.1810, Avg G Loss: 0.7527, Avg D Real Acc: 0.995, Avg D Fake Acc: 0.044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Summary - Avg D Loss: 0.2799, Avg G Loss: 0.7248, Avg D Real Acc: 0.992, Avg D Fake Acc: 0.033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Summary - Avg D Loss: 0.2389, Avg G Loss: 0.6729, Avg D Real Acc: 0.998, Avg D Fake Acc: 0.015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Summary - Avg D Loss: 0.2401, Avg G Loss: 0.6756, Avg D Real Acc: 0.993, Avg D Fake Acc: 0.028\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Summary - Avg D Loss: 0.2524, Avg G Loss: 0.6304, Avg D Real Acc: 0.991, Avg D Fake Acc: 0.014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Summary - Avg D Loss: 0.2786, Avg G Loss: 0.5658, Avg D Real Acc: 0.992, Avg D Fake Acc: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Summary - Avg D Loss: 0.2814, Avg G Loss: 0.5503, Avg D Real Acc: 0.994, Avg D Fake Acc: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Summary - Avg D Loss: 0.2781, Avg G Loss: 0.5549, Avg D Real Acc: 0.995, Avg D Fake Acc: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Summary - Avg D Loss: 0.2786, Avg G Loss: 0.5582, Avg D Real Acc: 0.995, Avg D Fake Acc: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Summary - Avg D Loss: 0.2758, Avg G Loss: 0.5569, Avg D Real Acc: 0.998, Avg D Fake Acc: 0.000\n",
      "\n",
      "Checkpoint saved for epoch 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Summary - Avg D Loss: 0.2748, Avg G Loss: 0.5622, Avg D Real Acc: 0.998, Avg D Fake Acc: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Summary - Avg D Loss: 0.2757, Avg G Loss: 0.5640, Avg D Real Acc: 0.998, Avg D Fake Acc: 0.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# --- Store metrics from this G step ---\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m current_g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Store the latest G loss for postfix\u001b[39;00m\n\u001b[1;32m    122\u001b[0m epoch_g_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m current_g_loss \u001b[38;5;66;03m# Accumulate total G loss\u001b[39;00m\n\u001b[1;32m    123\u001b[0m num_g_updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_loss_history = []\n",
    "g_loss_history = []\n",
    "\n",
    "d_real_acc_history = []\n",
    "d_fake_acc_history = []\n",
    "\n",
    "print(f\"Starting training with k_steps_D={k_steps_D}, k_steps_G={k_steps_G}...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    G.train()\n",
    "    D.train()\n",
    "\n",
    "    # Metrics accumulated over the epoch\n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    epoch_d_real_acc = 0.0 # Tracks accuracy on real images from the last D step in each batch cycle\n",
    "    epoch_d_fake_acc = 0.0 # Tracks accuracy on fake images from the last D step in each batch cycle\n",
    "    num_d_updates = 0\n",
    "    num_g_updates = 0\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for i, (real_images, real_labels) in progress_bar:\n",
    "\n",
    "        real_images = real_images.to(device)\n",
    "        real_labels = real_labels.to(device)\n",
    "        current_batch_size = real_images.size(0)\n",
    "\n",
    "        # Create targets for loss calculation\n",
    "        # Note: D uses smoothed real targets, G uses non-smoothed targets typically\n",
    "        real_target_smoothed = torch.full((current_batch_size, 1), (1.0 - label_smoothing), device=device)\n",
    "        real_target_unsmoothed = torch.ones(current_batch_size, 1, device=device) # For G loss\n",
    "        fake_target = torch.zeros(current_batch_size, 1, device=device)\n",
    "\n",
    "        # --- Store metrics for the current batch cycle ---\n",
    "        current_d_loss = 0.0\n",
    "        current_g_loss = 0.0\n",
    "        current_d_real_acc = 0.0\n",
    "        current_d_fake_acc = 0.0\n",
    "\n",
    "        # ---------------------------------\n",
    "        # Train Discriminator k_steps_D times\n",
    "        # ---------------------------------\n",
    "        for _ in range(k_steps_D):\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # --- Loss on Real Images ---\n",
    "            d_real_output = D(real_images, real_labels)\n",
    "            if d_real_output.shape != real_target_smoothed.shape:\n",
    "                 raise ValueError(f\"Shape mismatch D real: D output {d_real_output.shape}, target {real_target_smoothed.shape}\")\n",
    "            d_real_loss = criterion(d_real_output, real_target_smoothed)\n",
    "\n",
    "            # --- Loss on Fake Images ---\n",
    "            z = torch.randn(current_batch_size, noise_dim, device=device)\n",
    "            # Sample fake labels respecting class distribution\n",
    "            fake_labels_dist = torch.multinomial(class_weights, current_batch_size, replacement=True)\n",
    "\n",
    "            # Generate fake images - detach G's graph\n",
    "            with torch.no_grad():\n",
    "                fake_images = G(z, fake_labels_dist).detach()\n",
    "\n",
    "            d_fake_output = D(fake_images, fake_labels_dist)\n",
    "            if d_fake_output.shape != fake_target.shape:\n",
    "                 raise ValueError(f\"Shape mismatch D fake: D output {d_fake_output.shape}, target {fake_target.shape}\")\n",
    "            d_fake_loss = criterion(d_fake_output, fake_target)\n",
    "\n",
    "            # --- Total D Loss and Update ---\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # --- Store metrics from this D step ---\n",
    "            current_d_loss = d_loss.item() # Store the latest D loss for postfix\n",
    "            epoch_d_loss += current_d_loss # Accumulate total D loss\n",
    "            num_d_updates += 1\n",
    "\n",
    "            # Calculate accuracy only for the *last* D update in this cycle for epoch avg.\n",
    "            if _ == k_steps_D - 1:\n",
    "                 current_d_real_acc = ((torch.sigmoid(d_real_output) > 0.5).float().mean()).item() # Use sigmoid for accuracy check\n",
    "                 current_d_fake_acc = ((torch.sigmoid(d_fake_output) < 0.5).float().mean()).item() # Use sigmoid for accuracy check\n",
    "                 epoch_d_real_acc += current_d_real_acc\n",
    "                 epoch_d_fake_acc += current_d_fake_acc\n",
    "\n",
    "\n",
    "        # ---------------------------------\n",
    "        # Train Generator k_steps_G times\n",
    "        # ---------------------------------\n",
    "        # Only proceed if G needs updates (prevents unnecessary computation if k_steps_G=0)\n",
    "        if k_steps_G > 0:\n",
    "            # Prevent D gradients from affecting G updates\n",
    "            # (May not be strictly necessary if D params aren't used in G loss path,\n",
    "            # but good practice)\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            for _ in range(k_steps_G):\n",
    "                optimizer_G.zero_grad()\n",
    "\n",
    "                # --- Generate New Fake Data ---\n",
    "                z = torch.randn(current_batch_size, noise_dim, device=device)\n",
    "                # Sample fake labels respecting class distribution\n",
    "                fake_labels_dist_g = torch.multinomial(class_weights, current_batch_size, replacement=True)\n",
    "                fake_images_g = G(z, fake_labels_dist_g)\n",
    "\n",
    "                # --- Calculate G Loss (trying to fool D) ---\n",
    "                g_output = D(fake_images_g, fake_labels_dist_g)\n",
    "\n",
    "                # Use non-smoothed real targets for G's objective\n",
    "                if g_output.shape != real_target_unsmoothed.shape:\n",
    "                    raise ValueError(f\"Shape mismatch G: D output {g_output.shape}, target {real_target_unsmoothed.shape}\")\n",
    "\n",
    "                # G wants D to predict fake images as real (output logits close to 1)\n",
    "                g_loss = criterion(g_output, real_target_unsmoothed)\n",
    "\n",
    "                # --- Backpropagation and Update G ---\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # --- Store metrics from this G step ---\n",
    "                current_g_loss = g_loss.item() # Store the latest G loss for postfix\n",
    "                epoch_g_loss += current_g_loss # Accumulate total G loss\n",
    "                num_g_updates += 1\n",
    "\n",
    "            # Re-enable D gradients for the next D update cycle\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "\n",
    "        # --- Update Progress Bar ---\n",
    "        # Display the losses/accuracies from the *last* D and G steps of this batch cycle\n",
    "        progress_bar.set_postfix({\n",
    "            'D Loss': f\"{current_d_loss:.4f}\",\n",
    "            'G Loss': f\"{current_g_loss:.4f}\" if k_steps_G > 0 else \"N/A\",\n",
    "            'D Real Acc': f\"{current_d_real_acc:.3f}\",\n",
    "            'D Fake Acc': f\"{current_d_fake_acc:.3f}\"\n",
    "        })\n",
    "        progress_bar.update(1) # Increment progress bar\n",
    "\n",
    "    progress_bar.close() # Close the tqdm bar for the epoch\n",
    "\n",
    "    # --- End of Epoch Calculations and Logging ---\n",
    "    # Calculate average losses and accuracies for the epoch\n",
    "    avg_d_loss = epoch_d_loss / num_d_updates if num_d_updates > 0 else 0\n",
    "    avg_g_loss = epoch_g_loss / num_g_updates if num_g_updates > 0 else 0\n",
    "    # Average accuracies are over the number of batch cycles (len(data_loader))\n",
    "    avg_d_real_acc = epoch_d_real_acc / len(data_loader) if len(data_loader) > 0 else 0\n",
    "    avg_d_fake_acc = epoch_d_fake_acc / len(data_loader) if len(data_loader) > 0 else 0\n",
    "\n",
    "    d_loss_history.append(avg_d_loss)\n",
    "    g_loss_history.append(avg_g_loss)\n",
    "    d_real_acc_history.append(avg_d_real_acc)\n",
    "    d_fake_acc_history.append(avg_d_fake_acc)\n",
    "\n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar('Loss/Discriminator_Avg', avg_d_loss, epoch)\n",
    "    writer.add_scalar('Loss/Generator_Avg', avg_g_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/D_Real_Avg', avg_d_real_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/D_Fake_Avg', avg_d_fake_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Summary - \"\n",
    "          f\"Avg D Loss: {avg_d_loss:.4f}, Avg G Loss: {avg_g_loss:.4f}, \"\n",
    "          f\"Avg D Real Acc: {avg_d_real_acc:.3f}, Avg D Fake Acc: {avg_d_fake_acc:.3f}\\n\")\n",
    "\n",
    "    # --- Generate and Save Sample Images ---\n",
    "    if (epoch + 1) % log_interval == 0 or epoch == 0 or epoch == num_epochs - 1:\n",
    "        G.eval() # Set G to evaluation mode for generation\n",
    "        fake_samples, sample_labels = generate_samples(num_samples=16, fixed_noise=fixed_noise, fixed_labels=fixed_labels)\n",
    "        fig = create_image_grid(fake_samples, sample_labels, nrow=4) # Assuming nrow=4\n",
    "\n",
    "        # Save figure to TensorBoard\n",
    "        writer.add_figure(f'Generated Traffic Signs/Epoch {epoch+1}', fig, global_step=epoch)\n",
    "\n",
    "        # Save figure to disk\n",
    "        os.makedirs('generated_samples', exist_ok=True)\n",
    "        fig.savefig(f'generated_samples/epoch_{epoch+1:04d}.png') # Use padding for sorting\n",
    "        plt.close(fig) # Close the figure to free memory\n",
    "        G.train() # Set G back to training mode\n",
    "\n",
    "    # --- Save Checkpoint ---\n",
    "    if (epoch + 1) % checkpoint_interval == 0 or epoch == num_epochs - 1:\n",
    "        os.makedirs('checkpoints', exist_ok=True)\n",
    "        \n",
    "        # delete old checkpoints to save space\n",
    "        checkpoints = sorted(os.listdir('checkpoints'))\n",
    "        if len(checkpoints) > 5:\n",
    "            for old_checkpoint in checkpoints[:-1]:\n",
    "                os.remove(os.path.join('checkpoints', old_checkpoint))\n",
    "                print(f\"Deleted old checkpoint: {old_checkpoint}\")\n",
    "                \n",
    "        save_checkpoint(G, D, optimizer_G, optimizer_D, epoch, f'checkpoints/cgan_gtsrb_ksteps_epoch_{epoch+1:04d}.pth')\n",
    "        print(f\"Checkpoint saved for epoch {epoch+1}.\")\n",
    "\n",
    "# --- End of Training ---\n",
    "# Save final model explicitly\n",
    "save_checkpoint(G, D, optimizer_G, optimizer_D, num_epochs, 'checkpoints/cgan_gtsrb_ksteps_final.pth')\n",
    "\n",
    "print(\"Training complete!\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Assume Training Loop Finished ---\n",
    "# Make sure these lists exist and are populated correctly:\n",
    "# d_loss_history = [...] # Avg D loss per epoch\n",
    "# g_loss_history = [...] # Avg G loss per epoch\n",
    "# d_real_acc_history = [...] # Avg D real accuracy per epoch\n",
    "# d_fake_acc_history = [...] # Avg D fake accuracy per epoch\n",
    "\n",
    "print(\"\\nPlotting loss and accuracy history...\")\n",
    "\n",
    "# --- Directory for Plots ---\n",
    "plot_dir = 'plots'\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# --- Plot Losses ---\n",
    "if d_loss_history and g_loss_history:\n",
    "    epochs = range(1, len(d_loss_history) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, g_loss_history, label='Generator Average Loss', color='deepskyblue')\n",
    "    plt.plot(epochs, d_loss_history, label='Discriminator Average Loss', color='salmon')\n",
    "    plt.title('Average Generator and Discriminator Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (BCEWithLogitsLoss)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Save the loss plot\n",
    "    loss_plot_filename = os.path.join(plot_dir, 'gan_loss_history.png')\n",
    "    try:\n",
    "        plt.savefig(loss_plot_filename)\n",
    "        print(f\"Loss graph saved to: {loss_plot_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving loss graph: {e}\")\n",
    "    plt.show() # Optional: Show interactively\n",
    "    plt.close() # Close the figure\n",
    "else:\n",
    "    print(\"Skipping loss plot (history lists missing or empty).\")\n",
    "\n",
    "\n",
    "# --- Plot Accuracies ---\n",
    "# Make sure history lists for accuracy exist\n",
    "if d_real_acc_history and d_fake_acc_history:    \n",
    "    \n",
    "    # Define epochs if not already defined (in case loss plot was skipped)\n",
    "    if 'epochs' not in locals():\n",
    "        epochs = range(1, len(d_real_acc_history) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Plot the ACTUAL accuracy histories\n",
    "    plt.plot(epochs, d_real_acc_history, label='Discriminator Real Accuracy', color='forestgreen')\n",
    "    plt.plot(epochs, d_fake_acc_history, label='Discriminator Fake Accuracy', color='darkorange')\n",
    "    plt.title('Average Discriminator Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1.05) # Set Y-axis limits for accuracy (0 to 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Save the accuracy plot\n",
    "    acc_plot_filename = os.path.join(plot_dir, 'gan_accuracy_history.png')\n",
    "    try:\n",
    "        plt.savefig(acc_plot_filename)\n",
    "        print(f\"Accuracy graph saved to: {acc_plot_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving accuracy graph: {e}\")\n",
    "    plt.show() # Optional: Show interactively\n",
    "    plt.close() # Close the figure\n",
    "else:\n",
    "    print(\"Skipping accuracy plot (history lists missing or empty).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model explicitly\n",
    "save_name = \"goodrun_c2\"\n",
    "save_path = os.path.join('models', f'{save_name}.pth')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# save the model weights\n",
    "\n",
    "torch.save({\n",
    "    'generator_state_dict': G.state_dict(),\n",
    "    'discriminator_state_dict': D.state_dict(),\n",
    "    'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "    'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "}, save_path)\n",
    "print(f\"Final model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final samples\n",
    "fake_samples, sample_labels = generate_samples(num_samples=36)\n",
    "fig = create_image_grid(fake_samples, sample_labels, nrow=6)\n",
    "# fig.savefig('final_generated_samples.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
