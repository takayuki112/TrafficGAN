{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/takayuki/Desktop/sem6/DL/mini_proj_TRAFFIC/data/'\n",
    "train_dir = os.path.join(data_dir, 'preprocessed', 'Train')\n",
    "\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "    transforms.RandomRotation(15),\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root = train_dir, transform=data_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with training the GAN on class id = 0, which is the minority class here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 0\n",
    "batchSize = 8\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "zdims = 100\n",
    "\n",
    "label_offset = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Datset size:  210\n"
     ]
    }
   ],
   "source": [
    "index = full_dataset.class_to_idx[str(class_id)]\n",
    "class_dataset = [sample for sample in full_dataset.samples if sample[1] == index]\n",
    "\n",
    "class_loader = DataLoader(class_dataset, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "print(\"Class Datset size: \", len(class_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gangen.dcgan import Generator, Discriminator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "\n",
    "G = Generator(z_dims=zdims).to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=learning_rate)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Training...\n",
    "1. create label vectors of 0s & 1s \n",
    "    - these can also be made 0.1 and 0.9 if the D is becoming too confident too quickly\n",
    "    - one might consider gradually pushing them from 0.1 to 0 and 0.9 to 1 as training progresses and the Generator gets better ??\n",
    "2. Train D with real images and take a step with d_optimizer\n",
    "3. Generate a batch of fake images using G, from a batch of vectors - z sampled from standard normal distr\n",
    "4. Train D on this batch of generated images and those fake_labels from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "d_accuracy_list = []\n",
    "\n",
    "\n",
    "\n",
    "# 1. create label vectors of 0s & 1s \n",
    "real_labels = torch.ones(batchSize, 1, device=device, dtype=torch.float32) - label_offset\n",
    "fake_labels = torch.zeros(batchSize, 1, device=device, dtype=torch.float32) + label_offset\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    rdloss = 0\n",
    "    rdcorr = 0\n",
    "    rgloss = 0\n",
    "    \n",
    "    for real_images, _ in class_loader:\n",
    "        real_images = real_images.to(device)\n",
    "        \n",
    "        # 2. Train D with this batch of real images and take a step with d_optimizer\n",
    "        d_out = D(real_images)\n",
    "        d_loss = criterion(d_out, real_labels)\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        rdloss += d_loss.item()\n",
    "        rdcorr += (d_out > 0.5).sum().item()        \n",
    "        # 3. Generate a batch of fake images using G, from a batch of vectors - z sampled from standard normal distr\n",
    "        z = torch.randn(batchSize, zdims, 1, 1, device=device, dtype=torch.float32)\n",
    "        fake_images = G(z).detach()\n",
    "        \n",
    "        # 4. Train D on this batch of generated images  and those fake_labels \n",
    "        d_out_fakes = D(fake_images)\n",
    "        d_loss = criterion(d_out_fakes, fake_labels)\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        rdloss += d_loss.item()\n",
    "        rdcorr += (d_out < 0.5).sum().item()        \n",
    "        \n",
    "        # 5. Train Generator to have those fake images get matched with the real labels\n",
    "        fake_images = G(z)\n",
    "        d_out_fakes = D(fake_images)\n",
    "        g_loss = criterion(d_out_fakes, real_labels)\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        rgloss += g_loss.item()\n",
    "        \n",
    "    csize = max(len(class_loader), 1)\n",
    "    d_acc = rdcorr / (2 * csize * batchSize)\n",
    "    rdloss /= 2*csize\n",
    "    rgloss /= csize\n",
    "    \n",
    "    d_loss_list.append(rdloss)\n",
    "    g_loss_list.append(rgloss)\n",
    "    d_accuracy_list.append(d_acc)\n",
    "    \n",
    "    print(f\"Epoch {ep+1}/{num_epochs} | D Loss: {rdloss:.4f}, G Loss: {rgloss:.4f}, D Accuracy: {d_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
